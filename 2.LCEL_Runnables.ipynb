{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eae6f7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f310f75",
   "metadata": {},
   "source": [
    "## Simple Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "781f9630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatModel = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd55b725",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"error\":\"Forbidden\"}\\\\n\\')')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One curious fact about Donald Trump is that he was the first U.S"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"error\":\"Forbidden\"}\\\\n\\')')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". president to have never held a political office or served in the military prior to his election in 2016. His background was primarily in business and entertainment, which set him apart from his predecessors and contributed to his unconventional approach to politics."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"error\":\"Forbidden\"}\\\\n\\')')\n",
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"error\":\"Forbidden\"}\\\\n\\')')\n",
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"error\":\"Forbidden\"}\\\\n\\')')\n",
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"error\":\"Forbidden\"}\\\\n\\')')\n",
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"error\":\"Forbidden\"}\\\\n\\')')\n",
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"error\":\"Forbidden\"}\\\\n\\')')\n",
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"error\":\"Forbidden\"}\\\\n\\')')\n",
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"error\":\"Forbidden\"}\\\\n\\')')\n",
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"error\":\"Forbidden\"}\\\\n\\')')\n",
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"error\":\"Forbidden\"}\\\\n\\')')\n",
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"error\":\"Forbidden\"}\\\\n\\')')\n",
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"error\":\"Forbidden\"}\\\\n\\')')\n",
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"error\":\"Forbidden\"}\\\\n\\')')\n",
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"error\":\"Forbidden\"}\\\\n\\')')\n",
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"error\":\"Forbidden\"}\\\\n\\')')\n",
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"error\":\"Forbidden\"}\\\\n\\')')\n",
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"error\":\"Forbidden\"}\\\\n\\')')\n",
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"error\":\"Forbidden\"}\\\\n\\')')\n",
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"error\":\"Forbidden\"}\\\\n\\')')\n",
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"error\":\"Forbidden\"}\\\\n\\')')\n",
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"error\":\"Forbidden\"}\\\\n\\')')\n",
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"error\":\"Forbidden\"}\\\\n\\')')\n",
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"error\":\"Forbidden\"}\\\\n\\')')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a curious fact about {politician}\")\n",
    "\n",
    "chain = prompt | chatModel | StrOutputParser()\n",
    "\n",
    "# Stream and print clean text\n",
    "for chunk in chain.stream({\"politician\": \"Donald Trump\"}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b187c873",
   "metadata": {},
   "source": [
    "## LCEL\n",
    "* LCEL has become the backbone of the newest versions of LangChain.\n",
    "* Traditional chains are still supported, but treated as \"Legacy\" and have less functionality than the new LCEL chains.\n",
    "* Many students struggle with LCEL.\n",
    "\n",
    "### Main goals of LCEL\n",
    "* Make it easy to build chains in a compact way.\n",
    "* Support advanced LangChain functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ec89f1",
   "metadata": {},
   "source": [
    "### Legacy Chain vs. LCEL Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df9bf93",
   "metadata": {},
   "source": [
    "#### Legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a03eca07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xenow\\Downloads\\MyGitRepos\\ownLangChainNotes\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'One curious fact about Diego Maradona is that he was famously known for his \"Hand of God\" goal during the 1986 FIFA World Cup quarter-final match against England. However, what many people might not know is that Maradona also scored one of the greatest goals in World Cup history in the same match. Just minutes after the controversial Hand of God goal, he dribbled past five England players over a distance of 60 meters to score what is often referred to as the \"Goal of the Century.\" This incredible display of skill and determination showcased his extraordinary talent and remains a defining moment in football history.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a curious fact about {soccer_player}\")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "traditional_chain = LLMChain(\n",
    "    llm=chatModel,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "traditional_chain.predict(soccer_player=\"Maradona\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48b5091",
   "metadata": {},
   "source": [
    "### LCEL Chain\n",
    "* The \"pipe\" operator `|` is the main element of the LCEL chains.\n",
    "* The order (left to right) of the elements in a LCEL chain matters.\n",
    "* An LCEL Chain is a Sequence of Runnables.\n",
    "\n",
    "* All the components of the chain are Runnables.\n",
    "* When we write chain.invoke() we are using invoke with all the componentes of the chain in an orderly manner:\n",
    "    * First, we apply .invoke() to the prompt.\n",
    "    * Then, with the previous output, we apply .invoke() to the model.\n",
    "    * And finally, with the previous output, we apply .invoke() to the output parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3216fdd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A curious fact about Cristiano Ronaldo is that he has a unique goal celebration known as the \"Siii!\" celebration, which involves him jumping into the air, twisting in mid-air, and landing while shouting \"Siii!\" (which means \"Yes!\" in Spanish). This celebration has become iconic among fans and is often mimicked by young soccer players around the world. Interestingly, Ronaldo first popularized this celebration while playing for Real Madrid, and it has since become synonymous with his brand and personality on and off the pitch.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | chatModel | output_parser\n",
    "\n",
    "chain.invoke({\"soccer_player\": \"Ronaldo\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b2c85ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One curious fact about Cristiano Ronaldo is that he has a unique dietary regimen that includes a strict focus on protein and hydration. He reportedly eats six small meals a day, which often include foods like chicken, fish, vegetables, and whole grains. Additionally, he avoids sugary drinks and prefers to stay hydrated with water. Ronaldo's commitment to his diet is part of what he believes contributes to his longevity and performance in professional football, allowing him to maintain an elite level of fitness even into his late 30s."
     ]
    }
   ],
   "source": [
    "# Stream and print clean text\n",
    "for chunk in chain.stream({\"soccer_player\": \"Ronaldo\"}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262bed3c",
   "metadata": {},
   "source": [
    "### LCEL: The runnable execution order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dd6c77",
   "metadata": {},
   "source": [
    "![alt text](./lcel-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e73843",
   "metadata": {},
   "source": [
    "* All the components of the chain are Runnables.\n",
    "* **When we write chain.invoke() we are using invoke with all the componentes of the chain in an orderly manner**:\n",
    "    * First, we apply .invoke() with the user input to the prompt template.\n",
    "    * Then, with the completed prompt, we apply .invoke() to the model.\n",
    "    * And finally, we apply .invoke() to the output parser with the output of the model.\n",
    "* IMPORTANT: the order of operations in a chain matters. If you try to execute the previous chain with the components in different order, the chain will fail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48775f0",
   "metadata": {},
   "source": [
    "#### Invoke vs Stream vs Batching\n",
    "\n",
    "LCEL Chains/Runnables are used with:\n",
    "* chain.invoke(): call the chain on an input.\n",
    "* chain.stream(): call the chain on an input and stream back chunks of the response.\n",
    "* chain.batch(): call the chain on a list of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63a12c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"Tell me one sentence about {politician}.\")\n",
    "chain = prompt | chatModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60145509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Winston Churchill was a British statesman, military leader, and prime minister known for his leadership during World War II and his powerful speeches that inspired resilience in the face of adversity.', response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 14, 'total_tokens': 50, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'finish_reason': 'stop', 'logprobs': None}, id='run-d22af371-7620-49f2-b5c7-7a9a08d7d5e8-0', usage_metadata={'input_tokens': 14, 'output_tokens': 36, 'total_tokens': 50})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoke\n",
    "chain.invoke({\"politician\": \"Churchill\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0ef1fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Franklin D. Roosevelt was the 32nd President of the United States, serving from 1933 to 1945, and is best known for leading the country through the Great Depression and World War II while implementing the New Deal to promote economic recovery and social reform."
     ]
    }
   ],
   "source": [
    "# stream\n",
    "for s in chain.stream({\"politician\": \"F.D. Roosevelt\"}):\n",
    "    print(s.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9853c7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Vladimir Lenin was a revolutionary leader who played a key role in the Russian Revolution of 1917 and the establishment of the Soviet Union, advocating for Marxist principles and the idea of a vanguard party to guide the working class.', response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 14, 'total_tokens': 61, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'finish_reason': 'stop', 'logprobs': None}, id='run-b0857daf-6eae-443d-8ad7-84d55672865b-0', usage_metadata={'input_tokens': 14, 'output_tokens': 47, 'total_tokens': 61}),\n",
       " AIMessage(content='Joseph Stalin was the leader of the Soviet Union from the mid-1920s until his death in 1953, known for his totalitarian regime, rapid industrialization, and widespread purges.', response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 14, 'total_tokens': 54, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'finish_reason': 'stop', 'logprobs': None}, id='run-de451a34-dfc9-499a-992a-985466731d83-0', usage_metadata={'input_tokens': 14, 'output_tokens': 40, 'total_tokens': 54})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch\n",
    "chain.batch([{\"politician\": \"Lenin\"}, {\"politician\": \"Stalin\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4412e4fb",
   "metadata": {},
   "source": [
    "#### LCEL Chains/Runnables can be also used asynchronously:\n",
    "* chain.ainvoke(): call the chain on an input.\n",
    "* chain.astream(): call the chain on an input and stream back chunks of the response.\n",
    "* chain.abatch(): call the chain on a list of inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61912a5",
   "metadata": {},
   "source": [
    "### RunnablePassthrough\n",
    "* It does not do anything to the input data.\n",
    "* Let's see it in a very simple example: a chain with just RunnablePassthrough() will output the original input without any modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f126cb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Abram'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = RunnablePassthrough()\n",
    "\n",
    "chain.invoke(\"Abram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc004961",
   "metadata": {},
   "source": [
    "### RunnableLambda\n",
    "* To use a custom function inside a LCEL chain we need to wrap it up with RunnableLambda.\n",
    "* Let's define a very simple function to create Russian lastnames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e46b198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def russian_lastname(name: str) -> str:\n",
    "    return f\"{name}ovich\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "414c727e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Abramovich'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "chain = RunnablePassthrough() | RunnableLambda(russian_lastname)\n",
    "\n",
    "chain.invoke(\"Abram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e2f63c",
   "metadata": {},
   "source": [
    "### RunnableParallel (Important)\n",
    "* We will use RunnableParallel() for running tasks in parallel.\n",
    "* This is probably the most important and most useful Runnable from LangChain.\n",
    "* In the following chain, RunnableParallel is going to run these two tasks in parallel:\n",
    "    * operation_a will use RunnablePassthrough.\n",
    "    * operation_b will use RunnableLambda with the russian_lastname function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1393f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "chain = RunnableParallel(\n",
    "    {\n",
    "        \"operation_a\": RunnablePassthrough(),\n",
    "        \"operation_b\": RunnableLambda(russian_lastname)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8670ba41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'operation_a': 'Abram', 'operation_b': 'Abramovich'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Abram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9cfa13",
   "metadata": {},
   "source": [
    "* Instead of using RunnableLambda, now we are going to use a lambda function and we will invoke the chain with two inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4caed86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel(\n",
    "    {\n",
    "        \"operation_a\": RunnablePassthrough(),\n",
    "        \"soccer_player\": lambda x: x[\"name\"]+\"ovich\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4d33e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'operation_a': {'name1': 'Jordam', 'name': 'Abram'},\n",
       " 'soccer_player': 'Abramovich'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"name1\": \"Jordam\",\n",
    "    \"name\": \"Abram\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2765cb",
   "metadata": {},
   "source": [
    "* See how the lambda function is taking the \"name\" input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca0cca5",
   "metadata": {},
   "source": [
    "#### We can add more Runnables to the chain\n",
    "* In the following example, the prompt Runnable will take the output of the RunnableParallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70b8c5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"tell me a curious fact about {soccer_player}\")\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2617472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def russian_lastname_from_dictionary(person):\n",
    "    return person[\"name\"] + \"ovich\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2843a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel(\n",
    "    {\n",
    "        \"operation_a\": RunnablePassthrough(),\n",
    "        \"soccer_player\": RunnableLambda(russian_lastname_from_dictionary),\n",
    "        \"operation_c\": RunnablePassthrough(),\n",
    "    }\n",
    ") | prompt | chatModel | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce6876c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A curious fact about Roman Abramovich, the Russian billionaire and former owner of Chelsea Football Club, is that he has a background that includes not only business and sports but also a fascination with art. Abramovich is known for his extensive art collection, which features works by renowned artists such as Francis Bacon and Jean-Michel Basquiat. His interest in art led him to establish the Garage Museum of Contemporary Art in Moscow, a significant cultural institution that promotes contemporary art in Russia. This aspect of his life showcases a different side of Abramovich, beyond his business dealings and football interests.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"name1\": \"Jordam\",\n",
    "    \"name\": \"Abram\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a10c867",
   "metadata": {},
   "source": [
    "* As you saw, the prompt Runnable took \"Abramovich\", the output of the RunnableParallel, as the value for the \"soccer_player\" variable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
